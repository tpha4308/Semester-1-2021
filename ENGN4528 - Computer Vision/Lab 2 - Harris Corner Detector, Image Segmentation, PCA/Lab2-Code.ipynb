{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Lab 2 - ENGN4528 - 2021\n",
    "\n",
    "**Name:** Thao Pham  \n",
    "**Student ID:** u7205329  \n",
    "**Date:** 02/05/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Harris Corner Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2(img, conv_filter):\n",
    "    # flip the filter\n",
    "\n",
    "    f_siz_1, f_size_2 = conv_filter.shape\n",
    "    conv_filter = conv_filter[range(f_siz_1 - 1, -1, -1), :][:, range(f_siz_1 - 1, -1, -1)]\n",
    "    pad = (conv_filter.shape[0] - 1) // 2\n",
    "    result = np.zeros((img.shape))\n",
    "    img = np.pad(img, ((pad, pad), (pad, pad)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    filter_size = conv_filter.shape[0]\n",
    "    for r in np.arange(img.shape[0] - filter_size + 1):\n",
    "        for c in np.arange(img.shape[1] - filter_size + 1):\n",
    "            curr_region = img[r:r + filter_size, c:c + filter_size]\n",
    "            curr_result = curr_region * conv_filter\n",
    "            conv_sum = np.sum(curr_result)  # Summing the result of multiplication.\n",
    "            result[r, c] = conv_sum  # Saving the summation in the convolution layer feature map.\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial(shape=(3, 3), sigma=0.5):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m + 1, -n:n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2. * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, add more if needed\n",
    "thresh = 0.01\n",
    "\n",
    "# Calculate image derivatives \n",
    "\n",
    "def calculate_derivs(img):\n",
    "    dx = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "    dy = dx.transpose()\n",
    "    \n",
    "    Ix = conv2(img, dx)\n",
    "    Iy = conv2(img, dy)\n",
    "    \n",
    "    # This line underneath is to create a Gaussian 2D distribution\n",
    "    # of size 13 x 13\n",
    "    sigma = 2\n",
    "    \n",
    "    g = fspecial((max(1, np.floor(3 * sigma) * 2 + 1), max(1, np.floor(3 * sigma) * 2 + 1)), sigma)\n",
    "    Iy2 = conv2(np.power(Iy, 2), g)\n",
    "    Ix2 = conv2(np.power(Ix, 2), g)\n",
    "    Ixy = conv2(Ix * Iy, g)\n",
    "    \n",
    "    return Ix2, Iy2, Ixy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the missing parts, rewrite them to ‘harris.py’ as a python script, and design appropriate function signature (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Task: Compute the Harris Cornerness\n",
    "######################################################################\n",
    "\n",
    "def compute_Harris_cornerness(img, alpha, Ix2, Iy2, Ixy):\n",
    "    h,w = img.shape\n",
    "\n",
    "    Rmatrix = np.zeros(img.shape)\n",
    "    window = fspecial((5,5), 1)\n",
    "\n",
    "    for i in range(2,w-2):\n",
    "        for j in range(2,h-2):\n",
    "            \n",
    "            # Find the second-order matrix of each pixel\n",
    "            Ix2_window = np.multiply(Ix2[j-2:j+3, i-2:i+3], window)\n",
    "            Iy2_window = np.multiply(Iy2[j-2:j+3, i-2:i+3], window)\n",
    "            Ixy_window = np.multiply(Ixy[j-2:j+3, i-2:i+3], window)\n",
    "\n",
    "            sum_Ix2 = np.sum(Ix2_window)\n",
    "            sum_Iy2 = np.sum(Iy2_window)\n",
    "            sum_Ixy = np.sum(Ixy_window)\n",
    "            \n",
    "            M = np.array([[sum_Ix2, sum_Ixy], \n",
    "                          [sum_Ixy, sum_Iy2]])\n",
    "            \n",
    "            # Response value\n",
    "            r = np.linalg.det(M) - alpha*(np.trace(M)**2)\n",
    "\n",
    "            # Save the response value to a new matrix \n",
    "            Rmatrix[j,i] = r\n",
    "\n",
    "    return Rmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Task: Perform non-maximum suppression and\n",
    "#       thresholding, return the N corner points\n",
    "#       as an Nx2 matrix of x and y coordinates\n",
    "######################################################################\n",
    "\n",
    "def marking_corners(img, response_matrix, t, d):\n",
    "    corners = {}\n",
    "\n",
    "    h, w = img.shape\n",
    "    \n",
    "    # Thresholding\n",
    "    for j in range(h):\n",
    "        for i in range(w):\n",
    "            if response_matrix[j,i] > t:\n",
    "                corners[(j,i)] = response_matrix[j,i]\n",
    "                \n",
    "    # Sort the corners w.r.t to their response values in descending manner\n",
    "    corners_sorted = sorted(corners.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Create the final_corners list in preparation for NMS\n",
    "    final_corners = [corners_sorted[0]]\n",
    "\n",
    "    # Non-maximum suppresion\n",
    "    for potential_corner in corners_sorted:\n",
    "        within_radius = False\n",
    "        for chosen_corner in final_corners: \n",
    "            yp, xp = potential_corner[0]\n",
    "            y_chosen, x_chosen = chosen_corner[0]\n",
    "            \n",
    "            #If a potential corner is within a radius of 8 of any existing chosen corners,\n",
    "            # we will dismiss it\n",
    "            if (np.abs(xp - x_chosen) <= d) and (np.abs(yp - y_chosen) <= d):\n",
    "                within_radius = True\n",
    "                break\n",
    "                \n",
    "        # If not in conflict with any chosen corners, we will add it to the final list of corners        \n",
    "        if not within_radius:\n",
    "            final_corners.append(potential_corner)\n",
    "\n",
    "    # Return a Nx2 matrix of the pixel coordinates\n",
    "    yc, xc = [], []\n",
    "\n",
    "    for coord, Rval in final_corners:\n",
    "        y,x = coord\n",
    "        yc.append(y)\n",
    "        xc.append(x)\n",
    "\n",
    "    mat = np.column_stack((yc, xc))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test this function on the provided four test images (Harris-[1,2,3,4].jpg, they can be downloaded from Wattle). Display your results by marking the detected corners on the input images (using circles or crosses, etc) **(0.5 mark for each image, 2 marks in total)**.\n",
    "\n",
    "- Compare your results with that from python’s built-in function `cv2.cornerHarris()` **(0.5 mark)**, and discuss the factors that affect the performance of Harris corner detection **(1 mark)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = []\n",
    "for n in range(1, 5):\n",
    "    file = 'Task1/Harris_{}.jpg'.format(n)\n",
    "    img = cv2.imread(file, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_files.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for img in img_files:\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (12, 7))\n",
    "\n",
    "    # Own function\n",
    "    Ix2, Iy2, Ixy = calculate_derivs(img)\n",
    "    response_matrix = compute_Harris_cornerness(img, 0.04, Ix2, Iy2, Ixy)\n",
    "\n",
    "    threshold = np.max(response_matrix) * 0.01\n",
    "    M1 = marking_corners(img, response_matrix, threshold, 8)\n",
    "    \n",
    "    ys, xs = M1[:,0], M1[:, 1]\n",
    "    axs[0].imshow(img, cmap = 'gray')\n",
    "    axs[0].plot(xs, ys, '*', color='red', markersize = 4)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Built-in function\n",
    "    res = cv2.cornerHarris(img, 5, 9, 0.04)\n",
    "    threshold2 = np.max(res)*0.01\n",
    "    M2 = marking_corners(img, res, threshold2, 8)\n",
    "\n",
    "    ys2, xs2 = M2[:,0], M2[:, 1]\n",
    "    axs[1].imshow(img, cmap = 'gray')\n",
    "    axs[1].plot(xs2, ys2, '*', color='yellow', markersize = 4)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Task1/results/Harris-{}-result.png'.format(i))\n",
    "    plt.show()\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test this function on `Harris-5.jpg`. Analyse the results why we cannot get corners by discussing and visualising your corner response scores of the image. **(0.5 mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Task1/Harris-5.jpg'\n",
    "\n",
    "img = cv2.imread(file, 1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "Ix2, Iy2, Ixy = calculate_derivs(img)\n",
    "response_matrix = compute_Harris_cornerness(img, 0.04, Ix2, Iy2, Ixy)\n",
    "\n",
    "threshold = 0.01*np.max(response_matrix)\n",
    "M = marking_corners(img, response_matrix, threshold, 8)\n",
    "ys, xs = M[:,0], M[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (11, 4))\n",
    "\n",
    "axs[0].imshow(img, cmap = 'gray')\n",
    "axs[0].plot(xs, ys, '*', color='red', markersize = 2)\n",
    "axs[1].imshow(response_matrix, cmap = 'hot')\n",
    "axs[2].imshow(Iy2)\n",
    "\n",
    "i = 0\n",
    "for name in ('(a)', '(b)', '(c)'):\n",
    "    axs[i].set_title(name, fontsize = 12)\n",
    "    i += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Task1/results/Harris-5-results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test this function on `Harris-6.jpg`. Plot your harris corner detector results in your report and propose a solution to obtain the salient corners which is robust to noise. **(0.5 mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Task1/Harris-6.jpg'\n",
    "\n",
    "img = cv2.imread(file, 1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "Ix2, Iy2, Ixy = calculate_derivs(img)\n",
    "response_matrix = compute_Harris_cornerness(img, 0.04, Ix2, Iy2, Ixy)\n",
    "\n",
    "threshold = 0.01*np.max(response_matrix)\n",
    "M = marking_corners(img, response_matrix, threshold, 8)\n",
    "ys, xs = M[:,0], M[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gauss_filter(noisy_image, kernel):\n",
    "    height, width = noisy_image.shape\n",
    "    kernel_size = kernel.shape[0]\n",
    "    \n",
    "    half = kernel_size//2\n",
    "    \n",
    "    output_image = np.zeros((height, width), dtype = np.double)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            pixel = 0\n",
    "            for k in range(0, kernel_size):\n",
    "                for l in range(0, kernel_size):\n",
    "                    try:\n",
    "                        pixel += kernel[k,l]*noisy_image[i-half+k, j-half+l]\n",
    "                    except IndexError: \n",
    "                    # This is to deal with border cases, when an IndexError\n",
    "                    # is raised it means that we're trying to average with a pixel\n",
    "                    # outside of the boundary, so we set the pixel value to 0\n",
    "                        pixel += 0\n",
    "            output_image[i,j] = pixel\n",
    "        \n",
    "    # Clipping output image\n",
    "    output_image[output_image < 0] = 0\n",
    "    output_image[output_image > 255] = 255\n",
    "    \n",
    "    return output_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian filter to Harris-6\n",
    "\n",
    "img2 = my_gauss_filter(img, fspecial((7,7), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process for blurred Harris-6\n",
    "\n",
    "Ix2, Iy2, Ixy = calculate_derivs(img2)\n",
    "response_matrix = compute_Harris_cornerness(img2, 0.04, Ix2, Iy2, Ixy)\n",
    "\n",
    "#response_matrix = cv2.cornerHarris(img, 5, 13, 0.04)\n",
    "threshold = 0.01*np.max(response_matrix)\n",
    "M = marking_corners(img2, response_matrix, threshold, 8)\n",
    "ys2, xs2 = M[:,0], M[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "axs[0].imshow(img, cmap = 'gray')\n",
    "axs[0].plot(xs, ys, '*', color='red', markersize = 2)\n",
    "axs[0].set_title('(a)')\n",
    "axs[1].imshow(img2, cmap = 'gray')\n",
    "axs[1].plot(xs2, ys2, '*', color='red', markersize = 2)\n",
    "axs[1].set_title('(b)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Task1/results/Harris-6-result.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - K-Means Clustering and Colour Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your own K-means function `my_kmeans()`. The input is the data points to be processed and the number of clusters, and the output is several clusters of your data (you can use a cell array for clusters). Make sure each step in K-means is correct and clear, and comment on key code fragments **(1.5 marks)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sets k random data points in the data matrix to \n",
    "# be the initial k cluster centers\n",
    "\n",
    "def initialise_parameters(X, k):\n",
    "    npoints, dim = X.shape\n",
    "    C = np.zeros((k, dim))\n",
    "    \n",
    "    chosen_index = np.random.choice(npoints, k, replace = False)\n",
    "\n",
    "    for i in range(k):\n",
    "        C[i] = X[chosen_index[i]]\n",
    "     \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment(C, X):\n",
    "    L = np.zeros(X.shape)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        data_point = X[i]\n",
    "        \n",
    "        # Calculate the distance from the data point to each centroid\n",
    "        min_distance = 99999\n",
    "        closest_rep = None\n",
    "        \n",
    "        for j in range(len(C)):\n",
    "            current_centroid = C[j]\n",
    "            dist = np.linalg.norm(data_point - current_centroid)\n",
    "            if dist < min_distance:\n",
    "                closest_rep = current_centroid\n",
    "                min_distance = dist\n",
    "        \n",
    "        # Assignment \n",
    "        L[i] = closest_rep\n",
    "        i += 1\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_centroids(C, X, L):\n",
    "    total = []\n",
    "    count = []\n",
    "    \n",
    "    row, col = X.shape\n",
    "    for n in range(len(C)):\n",
    "        total.append(np.zeros(col))\n",
    "\n",
    "    count = [0 for n in range(len(C))]\n",
    "    \n",
    "    # Calculating the total and count for each cluster\n",
    "    for i in range(len(X)):\n",
    "        data_point = X[i]\n",
    "        \n",
    "        for n in range(len(C)):\n",
    "            if np.array_equal(L[i], C[n]):\n",
    "                total[n] += data_point\n",
    "                count[n] += 1\n",
    "\n",
    "    # Calculating the new centroids          \n",
    "    new_C = [total[n] / count[n] for n in range(len(total))]\n",
    "\n",
    "    return np.array(new_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kmeans(X, k):\n",
    "    L = np.zeros(X.shape)\n",
    "    C = initialise_parameters(X, k)\n",
    "    \n",
    "    niter = 0\n",
    "    i = 100 \n",
    "    old_C = C\n",
    "    \n",
    "    while niter < i:\n",
    "        L = assignment(C, X)\n",
    "        C = recalculate_centroids(C, X, L)\n",
    "\n",
    "        norm = np.linalg.norm(old_C - C, axis = 1)\n",
    "        stop = np.any(norm < 0.2)\n",
    "        if stop: \n",
    "            return L\n",
    "\n",
    "        old_C = C\n",
    "        niter += 1\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply your K-means function to color image segmentation. Each pixel should be represented as a 5-D vector that encodes: \n",
    "1. $L^∗$ - lightness of the color; \n",
    "2. $a^∗$ - the color position between red and green; \n",
    "3. $b^∗$ - the position between yellow and blue; \n",
    "4. x, y - pixel coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to display results\n",
    "\n",
    "def display_result(original_img, Z, res):\n",
    "    mat = np.zeros((original_img.shape))\n",
    "\n",
    "    for n in range(len(Z)):\n",
    "        row = Z[n,:]\n",
    "        row_class = res[n,:]\n",
    "        xc, yc = row[-2], row[-1]\n",
    "\n",
    "        mat[int(yc), int(xc)] = row_class[:3]\n",
    "\n",
    "    return cv2.cvtColor(mat.astype('uint8'), cv2.COLOR_Lab2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M&M Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "mm_og = cv2.imread('Task2/mandm.png', 1)\n",
    "mm_lab = cv2.cvtColor(mm_og, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "# 5d (with pixel coordinates)\n",
    "\n",
    "mm = mm_lab.astype('float32')\n",
    "X = []\n",
    "\n",
    "height, width = mm.shape[:2]\n",
    "for i in range(width):\n",
    "    for j in range(height):\n",
    "        att = []\n",
    "        for each in mm[j, i, :]:\n",
    "            att.append(each)\n",
    "        att.append(i)\n",
    "        att.append(j)\n",
    "        X.append(att)\n",
    "        \n",
    "mm_5d = np.array(X)\n",
    "\n",
    "# 3d (without pixel coordinates)\n",
    "mm_3d = mm.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare segmentation results using different numbers of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label7 = my_kmeans(mm_5d, 7)\n",
    "segmented_image7 = display_result(mm_og, mm_5d, label7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label20 = my_kmeans(mm_5d, 20)\n",
    "segmented_image20 = display_result(mm_og, mm_5d, label20)\n",
    "\n",
    "label40 = my_kmeans(mm_5d, 40)\n",
    "segmented_image40 = display_result(mm_og, mm_5d, label40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (10, 3))\n",
    "axs[0].imshow(segmented_image7)\n",
    "axs[1].imshow(segmented_image20)\n",
    "axs[2].imshow(segmented_image40)\n",
    "\n",
    "k_ls = [7, 20, 40]\n",
    "n = 0\n",
    "for ax in axs.flat:\n",
    "    ax.axis('off')\n",
    "    ax.set_title('k = {}'.format(k_ls[n]))\n",
    "    n += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Task2/results/Task2-M&M-5D.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare segmentation results with and without pixel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = mm_og.shape\n",
    "\n",
    "label7_3d = my_kmeans(mm_3d, 7)\n",
    "segmented7_3d = label7_3d.reshape(h,w,c)\n",
    "segmented7_3d_rgb = cv2.cvtColor(segmented7_3d.astype('uint8'), cv2.COLOR_Lab2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize =(6,3))\n",
    "\n",
    "axs[0].imshow(segmented_image7)\n",
    "axs[0].set_title('With pixel')\n",
    "axs[1].imshow(segmented7_3d_rgb)\n",
    "axs[1].set_title('Without pixel')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Task2/results/Task2-M&M-3D.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pepper picture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_og = cv2.imread('Task2/peppers.png', 1)\n",
    "fruit_lab = cv2.cvtColor(fruit_og, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "fruit = fruit_lab.astype('float')\n",
    "X_fruit = []\n",
    "\n",
    "height, width = fruit.shape[:2]\n",
    "for i in range(width):\n",
    "    for j in range(height):\n",
    "        att = []\n",
    "        for each in fruit[j, i, :]:\n",
    "            att.append(each)\n",
    "        att.append(i)\n",
    "        att.append(j)\n",
    "        X_fruit.append(att)\n",
    "        \n",
    "fruit_5d = np.array(X_fruit)\n",
    "\n",
    "# 3d (without pixel coordinates)\n",
    "fruit_3d = fruit.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare segmentation results using different numbers of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label7 = my_kmeans(fruit_5d, 7)\n",
    "segmented_image7 = display_result(fruit_og, fruit_5d, label7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label20 = my_kmeans(fruit_5d, 20)\n",
    "segmented_image20 = display_result(fruit_og, fruit_5d, label20)\n",
    "\n",
    "label40 = my_kmeans(fruit_5d, 40)\n",
    "segmented_image40 = display_result(fruit_og, fruit_5d, label40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (10, 3))\n",
    "axs[0].imshow(segmented_image7)\n",
    "axs[1].imshow(segmented_image20)\n",
    "axs[2].imshow(segmented_image40)\n",
    "\n",
    "k_ls = [7, 20, 40]\n",
    "n = 0\n",
    "for ax in axs.flat:\n",
    "    ax.axis('off')\n",
    "    ax.set_title('k = {}'.format(k_ls[n]))\n",
    "    n += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Task2/results/Task2-Fruit-5D.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare segmentation results with and without pixel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = fruit_og.shape\n",
    "\n",
    "label7_3d = my_kmeans(fruit_3d, 7)\n",
    "segmented7_3d = label7_3d.reshape(h,w,c)\n",
    "segmented7_3d_rgb = cv2.cvtColor(segmented7_3d.astype('uint8'), cv2.COLOR_Lab2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (7,3))\n",
    "\n",
    "axs[0].imshow(segmented_image7)\n",
    "axs[0].set_title('With pixel')\n",
    "axs[1].imshow(segmented7_3d_rgb)\n",
    "axs[1].set_title('Without pixel')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Task2/results/Task2-Fruit-3D.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard K-means algorithm is sensitive to initialization (e.g. initial cluster centres/seeds). One possible solution is to use `K-means++`, in which the initial seeds are forced to be far away from each other (to avoid local minimum). \n",
    "\n",
    "Please read the material http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf, summarize the key steps in the report (0.5 mark), and then implement K-means++ in your standard algorithm as a new initialization strategy (0.5 mark). \n",
    "\n",
    "Compare the image segmentation performance (e.g., in terms of convergence speed and segmentation results [by plotting the segmentation results in the report]) of this new strategy, with that of standard K-means, using different numbers of clusters and the same 5-D point representation, *namely [L, a*, b*, x, y] (L, a, b , pixel coordinates)* as that from previous question (0.5 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: K-means++\n",
    "\n",
    "def initialise_parameters_Kplus(X, k):\n",
    "    npoints, dim = X.shape\n",
    "    C = np.zeros((k, dim))\n",
    "    chosen_index = np.zeros(k)\n",
    "    \n",
    "    # Choose the first random centroid by select a random row\n",
    "    chosen_centroid = X[np.random.randint(0, npoints)]\n",
    "    C[0] = chosen_centroid\n",
    "    \n",
    "    # Use kmeans++ to find the other centroids\n",
    "    i = 0\n",
    "    while i < k-1:\n",
    "        new_X_index = []\n",
    "        Dx_list = []\n",
    "        \n",
    "        for j in range(len(X)):\n",
    "            data_point = X[j]\n",
    "            \n",
    "            if data_point not in C:\n",
    "                new_X_index.append(j)\n",
    "                \n",
    "                Dx = float('inf')\n",
    "                for centroid in C:\n",
    "                    distance = np.linalg.norm(data_point - centroid)\n",
    "                    Dx = min(Dx, distance)\n",
    "            \n",
    "                Dx_list.append(Dx**2)\n",
    "               \n",
    "        # Compute the new probability distribution     \n",
    "        sum_Dx = np.sum(Dx_list)\n",
    "        probs = np.array(Dx_list) / sum_Dx\n",
    "        \n",
    "        # Choose a new centroid\n",
    "        new_centroid_index = np.random.choice(new_X_index, 1, p = probs)\n",
    "        C[i+1] = X[new_centroid_index[0]]\n",
    "        i += 1\n",
    "        \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change my_kmeans function to specify method of initialisation\n",
    "\n",
    "def my_kmeans_changed(X, k, init):\n",
    "    L = np.zeros(X.shape)\n",
    "    \n",
    "    if init == 'plus':\n",
    "        C = initialise_parameters_Kplus(X, k)\n",
    "    elif init == 'normal':\n",
    "        C = initialise_parameters(X, k)\n",
    "    \n",
    "    tstart = process_time()\n",
    "    \n",
    "    niter = 0\n",
    "    i = 100 \n",
    "    old_C = C\n",
    "    \n",
    "    while niter < i:\n",
    "        L = assignment(C, X)\n",
    "        C = recalculate_centroids(C, X, L)\n",
    "\n",
    "        norm = np.linalg.norm(old_C - C, axis = 1)\n",
    "        stop = np.any(norm < 0.8)\n",
    "        if stop: \n",
    "            tstop = process_time()\n",
    "    \n",
    "            if init == 'plus':\n",
    "                print('Elapsed time with Kmeans++: {}'.format(tstop - tstart))\n",
    "            elif init == 'normal':\n",
    "                print('Elapsed time: {}'.format(tstop - tstart))\n",
    "            \n",
    "            return L\n",
    "\n",
    "        old_C = C\n",
    "        niter += 1\n",
    "        \n",
    "    tstop = process_time()\n",
    "    \n",
    "    if init == 'plus':\n",
    "        print('Elapsed time with Kmeans++: {}'.format(tstop - tstart))\n",
    "    elif init == 'normal':\n",
    "        print('Elapsed time: {}'.format(tstop - tstart))\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare running time\n",
    "\n",
    "label20_normal = my_kmeans_changed(fruit_5d, 20, 'normal')\n",
    "segmented_image20_normal = display_result(fruit_og, fruit_5d, label20_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label20_plus = my_kmeans_changed(fruit_5d, 20, 'plus')\n",
    "segmented_image20_plus = display_result(fruit_og, fruit_5d, label20_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare running time\n",
    "\n",
    "label40_normal = my_kmeans_changed(fruit_5d, 40, 'normal')\n",
    "segmented_image40_normal = display_result(fruit_og, fruit_5d, label40_normal)\n",
    "\n",
    "label40_plus = my_kmeans_changed(fruit_5d, 40, 'plus')\n",
    "segmented_image40_plus = display_result(fruit_og, fruit_5d, label40_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, constrained_layout = True,\n",
    "                       gridspec_kw = {'width_ratios': [1,7,7], 'height_ratios': [1,7,7]},\n",
    "                       figsize = (10, 7))\n",
    "\n",
    "axs[1][0].text(0.5, 0.5, 'k = 20', fontsize = 12)\n",
    "axs[2][0].text(0.5, 0.5, 'k = 40', fontsize = 12)\n",
    "axs[0][1].text(0.3, 0.5, 'Random initialisation', fontsize = 12)\n",
    "axs[0][2].text(0.4, 0.5, 'K-means++', fontsize = 12)\n",
    "\n",
    "axs[1][1].imshow(segmented_image20_normal)\n",
    "axs[2][1].imshow(segmented_image40_normal)\n",
    "\n",
    "axs[1][2].imshow(segmented_image20_plus)\n",
    "axs[2][2].imshow(segmented_image40_plus)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.savefig('Task2/results/Task2-KmeansPlus.png')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Face Recognition using Eigenface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an Eigen-face recognition system. Specifically, at least your face recognition system should be able to complete the following tasks:\n",
    "\n",
    "Read all the 135 training images from Yale-Face, represent each image as a single data point in a high dimensional space and collect all the data points into a big data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create data matrix\n",
    "\n",
    "path_wo_me = 'Task3/Yale-FaceA/trainingset'\n",
    "\n",
    "def make_matrix(path):\n",
    "    files = listdir(path)\n",
    "    files = [elem for elem in files if elem.endswith('.png')]\n",
    "    \n",
    "    \n",
    "    img0 = cv2.imread(\"{}/{}\".format(path, files[0]), 0)\n",
    "    h, w = img0.shape\n",
    "    \n",
    "    A = img0.flatten()\n",
    "    \n",
    "    for i in range(1, len(files)):\n",
    "        fname = \"{}/{}\".format(path, files[i])\n",
    "        img = cv2.imread(fname, 0)\n",
    "        img = img.flatten()\n",
    "        A = np.column_stack((A, img))\n",
    "        \n",
    "    return files, A.astype('float')\n",
    "\n",
    "files, A_wo_me = make_matrix(path_wo_me)\n",
    "h, w = 231, 195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA on the data matrix (1 mark), and display the mean face (1 mark). \n",
    "\n",
    "Given the size and the large number of input images, directly performing eigen value decomposition of the covariance matrix would be slow. Please read lecture notes and find a faster way to compute eigen values and vectors, explain the reason (1 mark) and implement it in your own code (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the mean face\n",
    "\n",
    "def make_mean_vector(data_matrix):\n",
    "    return np.mean(data_matrix, axis = 1)\n",
    "\n",
    "mean_vector = make_mean_vector(A_wo_me)\n",
    "mean_image = mean_vector.reshape(h,w)\n",
    "plt.imshow(mean_image.astype('uint8'), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.savefig('Task3/results/mean_face.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform PCA, \n",
    "# the function takes the data matrix, mean vector, and the number of \n",
    "# eigenfaces to choose\n",
    "\n",
    "def get_eigenfaces(data_matrix, mean_vector, k):\n",
    "    nfiles = data_matrix.shape[1]\n",
    "    \n",
    "    # Repeat the mean vector \n",
    "    mean_matrix = np.tile(mean_vector, (nfiles, 1))\n",
    "    \n",
    "    # Centered the data \n",
    "    A_centred = data_matrix - mean_matrix.T\n",
    "    \n",
    "    # Decompose A^T A\n",
    "    cov = (A_centred.T @ A_centred) \n",
    "    eigvals, eigvecs = np.linalg.eig(cov)\n",
    "    \n",
    "    # Get u = Av\n",
    "    u = np.array([A_centred@np.real(eigvecs[:,i]) for i in range(k)]).T\n",
    "    \n",
    "    # Normalised u\n",
    "    u_normalised = np.array([u[:,i] / np.linalg.norm(u[:,i]) for i in range(k)])\n",
    "    return u_normalised.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the top k principal components and visualize the top-k eigenfaces in your report (1 mark). You can choose k = 10 or k = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualise top 15 eigenfaces\n",
    "\n",
    "F = get_eigenfaces(A_wo_me, mean_vector, 15)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 5, figsize = (10, 7))\n",
    "n = 0\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        each = F[:,n]\n",
    "        each = each.reshape(h,w)\n",
    "        axs[i,j].imshow(each, cmap = 'gray')\n",
    "        axs[i,j].axis('off')\n",
    "        n += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig('Task3/results/Eigenfaces.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 10 test images in the Yale-Face dataset, please read in an image as the reference one, and determine its projection onto the basis spanned by the top k eigenfaces. Use this projection as feature to perform a `nearest-neighbour` search over all 135 faces, and find out the top three face images that are most similar to the reference one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Reduce Dimensionality \n",
    "# Takes in an image, the main k eigenfaces, mean vector\n",
    "# to project the img to a lower-dimensional subspace\n",
    "\n",
    "def reduce_reconstruct(img_path, F, mean_vector):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    img_vector = img.flatten()\n",
    "    \n",
    "    h,w = img.shape\n",
    "    \n",
    "    reconstruct = np.zeros((h*w))\n",
    "    dim, k = F.shape\n",
    "\n",
    "    for i in range(k):\n",
    "        eigface = F[:,i]\n",
    "        subtract = img_vector.astype(\"float\") - mean_vector\n",
    "        coeff = np.dot(eigface, subtract)\n",
    "        reconstruct += coeff*eigface\n",
    "        \n",
    "    result = np.add(reconstruct,mean_vector)\n",
    "    result = np.clip(result, 0, 255)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_train_faces = np.zeros(A_wo_me.shape)\n",
    "\n",
    "i = 0 \n",
    "for each in files:\n",
    "    training_file = '{}/{}'.format(path_wo_me, each)\n",
    "    reduce_each = reduce_reconstruct(training_file, F, mean_vector)\n",
    "    compressed_train_faces[:,i] = reduce_each\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Nearest Neighbour\n",
    "\n",
    "def nearest_images(test_image, compressed_train_faces, A):\n",
    "    compressed_test_image = reduce_reconstruct(test_image, F, mean_vector)\n",
    "    dim, npic = compressed_train_faces.shape\n",
    "    \n",
    "    distance_ls = []\n",
    "    for i in range(npic):\n",
    "        distance = np.linalg.norm(compressed_train_faces[:,i] - compressed_test_image)\n",
    "        distance_ls.append((distance, i))\n",
    "        \n",
    "    distance_ls = sorted(distance_ls)\n",
    "    \n",
    "    chosen_3files = np.zeros((dim, 3))\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        chosen_index = distance_ls[i][1]\n",
    "        chosen_3files[:,i] = A[:,chosen_index]\n",
    "    \n",
    "    return chosen_3files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfiles = listdir('Task3/Yale-FaceA/testset')\n",
    "testfiles = [elem for elem in testfiles if elem.endswith('.png')]\n",
    "\n",
    "for i in range(len(testfiles)):\n",
    "    test_filepath = 'Task3/Yale-FaceA/testset/' + testfiles[i]\n",
    "\n",
    "    res = nearest_images(test_filepath, compressed_train_faces, A_wo_me)\n",
    "    \n",
    "    test_img = cv2.imread(test_filepath, 0)\n",
    "    fig, axs = plt.subplots(1, 4)\n",
    "    axs[0].imshow(test_img, cmap = 'gray')\n",
    "    axs[0].axis('off')\n",
    "    for i in range(1, 1+3):\n",
    "        axs[i].imshow(res[:,i-1].reshape(h,w), cmap = 'gray')\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in one of your own frontal face images. Then run your face recognition system on this new image. Display the top 3 faces in the training folder that are most similar to your own face (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display\n",
    "\n",
    "me_test_path = 'Task3/Yale-FaceA/me-3-9.png'\n",
    "me_test_img = cv2.imread(me_test_path, 0)\n",
    "\n",
    "closest_3imgs_me1 = nearest_images(me_test_path, \n",
    "                                   compressed_train_faces, A_wo_me)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize = (8,3))\n",
    "\n",
    "axs[0].imshow(me_test_img, cmap = 'gray')\n",
    "\n",
    "for i in range(1, 1+3):\n",
    "    nb = closest_3imgs_me1[:,i-1].reshape(h,w)\n",
    "    axs[i].imshow(nb, cmap = 'gray') \n",
    "    \n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Task3/results/me.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the previous experiment by pre-adding the other 9 additional images of your face into the training set (a total of 144 training images).\n",
    "\n",
    "Note that you should make sure that your test face image is different from those included in the training set. Display the top 3 faces that are the closest to your face (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process with my images in the training set\n",
    "\n",
    "path_with_me = 'Task3/Yale-FaceA/trainingset-with-me'\n",
    "files, A_with_me = make_matrix(path_with_me)\n",
    "mean_vector = make_mean_vector(A_with_me)\n",
    "F = get_eigenfaces(A_with_me, mean_vector, 15)\n",
    "\n",
    "compressed_train_faces = np.zeros(A_with_me.shape)\n",
    "\n",
    "i = 0 \n",
    "for each in files:\n",
    "    training_file = path_with_me + '/' + each\n",
    "    reduce_each = reduce_reconstruct(training_file, F, mean_vector)\n",
    "    compressed_train_faces[:,i] = reduce_each\n",
    "    i+=1\n",
    "    \n",
    "closest_3imgs_me1 = nearest_images(me_test_path, compressed_train_faces, A_with_me)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize = (8,3))\n",
    "\n",
    "axs[0].imshow(me_test_img, cmap = 'gray')\n",
    "\n",
    "for i in range(1, 1+3):\n",
    "    nb = closest_3imgs_me1[:,i-1].reshape(h,w)\n",
    "    axs[i].imshow(nb, cmap = 'gray') \n",
    "    \n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Task3/results/me2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
